# image_captioning
This project uses OpenAI's CLIP model to match images with the most relevant captions by calculating cosine similarity between image and text embeddings. It enables accurate image understanding and caption ranking from a set of candidates.
